{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.           2.           3.         ...   5.           6.\n",
      "    7.        ]\n",
      " [  0.           0.          93.         ...  75.           0.\n",
      "   90.17721519]\n",
      " [ 93.         395.         100.         ...  75.           1.\n",
      "   82.        ]\n",
      " ...\n",
      " [126.          87.         133.         ... 160.           2.\n",
      "  193.        ]\n",
      " [133.          80.         140.         ... 160.           0.\n",
      "  185.        ]\n",
      " [140.          73.         147.         ... 160.           2.\n",
      "  189.        ]]\n",
      "(23826, 7)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn import preprocessing\n",
    "from sklearn import datasets, metrics\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import  classification_report, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "#試取資料\n",
    "file = open(\"feature/arkanoid_N5_20200824_10.pkl\", \"rb\")\n",
    "test = pickle.load(file)\n",
    "file.close()\n",
    "\n",
    "print(test)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 93. 395. 100. ...  75.   1.  82.]\n",
      " [100. 388. 107. ...  70.   0.  87.]\n",
      " [107. 381. 114. ...  70.   1.  82.]\n",
      " ...\n",
      " [174.  42. 167. ... 150.   0. 176.]\n",
      " [167.  49. 160. ... 155.   0. 179.]\n",
      " [160.  56. 153. ... 155.   2. 188.]]\n",
      "[[  0. 199.   7. ... 160.   2. 196.]\n",
      " [182.  77. 189. ... 110.   1. 121.]\n",
      " [119. 374. 126. ...  75.   0.  89.]\n",
      " ...\n",
      " [  7. 315.  14. ...  65.   2.  93.]\n",
      " [  0.  59.   7. ...  65.   1.  48.]\n",
      " [174. 333. 167. ...  85.   2. 113.]]\n",
      "(771673, 7)\n"
     ]
    }
   ],
   "source": [
    "## 初始化feature\n",
    "feature = np.array([1, 2, 3, 4, 5, 6, 7])\n",
    "#將所有矩陣疊加\n",
    "for i in range(1, 11):\n",
    "    path = \"feature/arkanoid_N5_20200824_\"+str(i*10)+\".pkl\"\n",
    "    file = open(path, \"rb\")\n",
    "    tmp = pickle.load(file)\n",
    "    #去除前兩筆資料後疊加\n",
    "    feature = np.vstack((feature, tmp[2:]))\n",
    "    file.close()\n",
    "for i in range(1, 11):\n",
    "    path = \"feature/arkanoid_N3_20200824_\"+str(i*10)+\".pkl\"\n",
    "    file = open(path, \"rb\")\n",
    "    tmp = pickle.load(file)\n",
    "    #去除前兩筆資料後疊加\n",
    "    feature = np.vstack((feature, tmp[2:]))\n",
    "    file.close()\n",
    "for i in range(1, 6):\n",
    "    path = \"feature/arkanoid_E5_20200824_\"+str(i*10)+\".pkl\"\n",
    "    file = open(path, \"rb\")\n",
    "    tmp = pickle.load(file)\n",
    "    #去除前兩筆資料後疊加\n",
    "    feature = np.vstack((feature, tmp[2:]))\n",
    "    file.close()\n",
    "for i in range(1, 6):\n",
    "    path = \"feature/arkanoid_E3_20200824_\"+str(i*10)+\".pkl\"\n",
    "    file = open(path, \"rb\")\n",
    "    tmp = pickle.load(file)\n",
    "    #去除前兩筆資料後疊加\n",
    "    feature = np.vstack((feature, tmp[2:]))\n",
    "    file.close()\n",
    "\n",
    "\n",
    "#要去除第一筆資料並洗牌\n",
    "feature = feature[1:]\n",
    "print(feature)\n",
    "#列洗牌\n",
    "np.random.seed(5)\n",
    "np.random.shuffle(feature)\n",
    "np.random.seed(97)\n",
    "np.random.shuffle(feature)\n",
    "np.random.seed(44)\n",
    "np.random.shuffle(feature)\n",
    "print(feature)\n",
    "\n",
    "#顯示資料數\n",
    "print(feature.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0. 199.   7. 192.]\n",
      " [182.  77. 189.  84.]\n",
      " [119. 374. 126. 367.]\n",
      " ...\n",
      " [  7. 315.  14. 322.]\n",
      " [  0.  59.   7.  52.]\n",
      " [174. 333. 167. 340.]]\n",
      "(771673, 4)\n",
      "[196. 121.  89. ...  93.  48. 113.]\n",
      "(771673,)\n"
     ]
    }
   ],
   "source": [
    "#[上一楨球的x, 上一楨球的y, x, y, 平台x值, 平台移動模式, 平台正確x值]\n",
    "#取出lightgbm需要的特徵(x_data)和對應的解(y_data)\n",
    "#濾掉平台正確x值\n",
    "x_data = feature[:, 0:4]\n",
    "print(x_data)\n",
    "print(x_data.shape)\n",
    "\n",
    "y_data = feature[:, 6]\n",
    "#y_data = y_data.reshape(y_data.size, 1)\n",
    "print(y_data)\n",
    "print(y_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  7.  -7.   7. 192.]\n",
      " [  7.   7. 189.  84.]\n",
      " [  7.  -7. 126. 367.]\n",
      " ...\n",
      " [  7.   7.  14. 322.]\n",
      " [  7.  -7.   7.  52.]\n",
      " [ -7.   7. 167. 340.]]\n",
      "(771673, 4)\n",
      "(771673,)\n"
     ]
    }
   ],
   "source": [
    "#現在球座標 - 先前球座標 = 方向 [可做可不做]\n",
    "x_data[0:, 0:2] = x_data[0:, 2:4] - x_data[0:, 0:2]\n",
    "print(x_data)\n",
    "print(x_data.shape)\n",
    "print(y_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "432996 170761 167916\n",
      "265080 2845 0\n",
      "total:  267925\n",
      "167916 167916 167916\n"
     ]
    }
   ],
   "source": [
    "#資料數量等化 [可做可不做]\n",
    "\n",
    "t0 = np.sum(y_data == 0)\n",
    "t1 = np.sum(y_data == 1)\n",
    "t2 = np.sum(y_data == 2)\n",
    "print(t0, t1, t2)\n",
    "\n",
    "#根據最小的值來做削減\n",
    "c0 = t0 - min(t0, t1, t2)\n",
    "c1 = t1 - min(t0, t1, t2)\n",
    "c2 = t2 - min(t0, t1, t2)\n",
    "print(c0, c1, c2)\n",
    "total = c0 + c1 + c2\n",
    "print(\"total: \", total)\n",
    "\n",
    "#由後往前，避免index改變\n",
    "for j in range(y_data.size-1, -1, -1):\n",
    "    print(c0 + c1 + c2, end='\\r')\n",
    "    if(y_data[j] == 0):\n",
    "        if(c0 != 0):\n",
    "            c0 -= 1\n",
    "            x_data = np.delete(x_data, j, axis = 0)\n",
    "            y_data = np.delete(y_data, j, axis = 0)\n",
    "    elif(y_data[j] == 1):\n",
    "        if(c1 != 0):\n",
    "            c1 -= 1\n",
    "            x_data = np.delete(x_data, j, axis = 0)\n",
    "            y_data = np.delete(y_data, j, axis = 0)\n",
    "    else:\n",
    "        if(c2 != 0):\n",
    "            c2 -= 1\n",
    "            x_data = np.delete(x_data, j, axis = 0)\n",
    "            y_data = np.delete(y_data, j, axis = 0)\n",
    "            \n",
    "    if(c0==0 and c1==0 and c2==0):\n",
    "        break\n",
    "\n",
    "f0 = np.sum(y_data == 0)\n",
    "f1 = np.sum(y_data == 1)\n",
    "f2 = np.sum(y_data == 2)\n",
    "print(f0, f1, f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#資料標準化 [可做可不做]\n",
    "# x_data = preprocessing.scale(x_data)\n",
    "# print(x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  7.  -7.   7. 192.]\n",
      " [  7.   7. 189.  84.]\n",
      " [  7.  -7. 126. 367.]\n",
      " ...\n",
      " [  7.   7.  14. 322.]\n",
      " [  7.  -7.   7.  52.]\n",
      " [ -7.   7. 167. 340.]]\n",
      "(771673, 4)\n",
      "[196. 121.  89. ...  93.  48. 113.]\n",
      "(771673,)\n"
     ]
    }
   ],
   "source": [
    "#訓練前最後資料狀愾確認\n",
    "print(x_data)\n",
    "print(x_data.shape)\n",
    "print(y_data)\n",
    "print(y_data.shape)\n",
    "\n",
    "#儲存陣列\n",
    "# file = open('arkanoid_N5N3E5E3_20200824_perpared_x_data.pkl', 'wb')\n",
    "# pickle.dump(x_data, file)\n",
    "# file.close()\n",
    "# file = open('arkanoid_N5N3E5E3_20200824_perpared_y_data.pkl', 'wb')\n",
    "# pickle.dump(y_data, file)\n",
    "# file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002175 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 509\n",
      "[LightGBM] [Info] Number of data points in the train set: 432136, number of used features: 4\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002390 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 509\n",
      "[LightGBM] [Info] Number of data points in the train set: 432136, number of used features: 4\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003049 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 509\n",
      "[LightGBM] [Info] Number of data points in the train set: 432136, number of used features: 4\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002371 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 509\n",
      "[LightGBM] [Info] Number of data points in the train set: 432136, number of used features: 4\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002813 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 509\n",
      "[LightGBM] [Info] Number of data points in the train set: 432136, number of used features: 4\n",
      "[50]\tcv_agg's rmse: 25.865 + 0.658934\n",
      "[100]\tcv_agg's rmse: 20.2622 + 0.519193\n",
      "[150]\tcv_agg's rmse: 18.279 + 0.389979\n",
      "[200]\tcv_agg's rmse: 17.209 + 0.408351\n",
      "[250]\tcv_agg's rmse: 16.2556 + 0.26653\n",
      "[300]\tcv_agg's rmse: 15.6639 + 0.258467\n",
      "[350]\tcv_agg's rmse: 14.9903 + 0.283276\n",
      "[400]\tcv_agg's rmse: 14.6509 + 0.249154\n",
      "[450]\tcv_agg's rmse: 14.1002 + 0.143853\n",
      "[500]\tcv_agg's rmse: 13.6261 + 0.121152\n",
      "[550]\tcv_agg's rmse: 13.1548 + 0.154334\n",
      "[600]\tcv_agg's rmse: 12.8893 + 0.102589\n",
      "[650]\tcv_agg's rmse: 12.5976 + 0.0944225\n",
      "[700]\tcv_agg's rmse: 12.3573 + 0.0931172\n",
      "[750]\tcv_agg's rmse: 12.1124 + 0.151922\n",
      "[800]\tcv_agg's rmse: 11.8653 + 0.155891\n",
      "[850]\tcv_agg's rmse: 11.5655 + 0.110548\n",
      "[900]\tcv_agg's rmse: 11.3746 + 0.12591\n",
      "[950]\tcv_agg's rmse: 11.199 + 0.102782\n",
      "[1000]\tcv_agg's rmse: 10.9935 + 0.0867172\n",
      "best n_estimators: 1000\n",
      "best cv score: 10.993509895891497\n"
     ]
    }
   ],
   "source": [
    "#資料劃分\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.3, random_state=9)\n",
    "data_train = lgb.Dataset(x_train, y_train, silent=True)\n",
    "#參數區間\n",
    "params = {\n",
    "    'boosting_type': 'gbdt', \n",
    "    'objective': 'regression', \n",
    "\n",
    "    'learning_rate': 0.1, \n",
    "    'num_leaves': 50, \n",
    "    'max_depth': 6,\n",
    "\n",
    "    'subsample': 0.8, \n",
    "    'colsample_bytree': 0.8, \n",
    "    }\n",
    "cv_results = lgb.cv(\n",
    "    params, data_train, num_boost_round=1000, nfold=5, stratified=False, shuffle=True, metrics='rmse',\n",
    "    early_stopping_rounds=50, verbose_eval=50, show_stdv=True, seed=0)\n",
    "\n",
    "print('best n_estimators:', len(cv_results['rmse-mean']))\n",
    "print('best cv score:', cv_results['rmse-mean'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lgb = lgb.LGBMRegressor(objective='regression',num_leaves=50,\n",
    "                              learning_rate=0.1, n_estimators=43, max_depth=6,\n",
    "                              metric='rmse', bagging_fraction = 0.8,feature_fraction = 0.8)\n",
    "\n",
    "params_test1={\n",
    "    'max_depth': range(3,8,2),\n",
    "    'num_leaves':range(50, 170, 30)\n",
    "}\n",
    "gsearch1 = GridSearchCV(estimator=model_lgb, param_grid=params_test1, scoring='neg_mean_squared_error', cv=5, verbose=1, n_jobs=4)\n",
    "gsearch1.fit(X_train, y_train)\n",
    "gsearch1.best_params_, gsearch1.best_score_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
